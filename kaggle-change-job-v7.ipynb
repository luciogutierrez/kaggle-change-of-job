{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from scipy import stats\r\n",
    "from sklearn.utils import resample\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import confusion_matrix, classification_report\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "pd.options.mode.chained_assignment = None\r\n",
    "pd.options.display.max_columns = None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ETL"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df_train = pd.read_csv('./datasets/z_train.csv')\r\n",
    "df_target = pd.read_csv('./datasets/z_test.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# df_train.head(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_train.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['enrollee_id', 'city', 'city_development_index', 'gender',\n",
       "       'relevent_experience', 'enrolled_university', 'education_level',\n",
       "       'major_discipline', 'experience', 'company_size', 'company_type',\n",
       "       'last_new_job', 'training_hours', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Elección de variables para el modelo\r\n",
    "# model_cols = ['enrollee_id','city','city_development_index','gender','relevent_experience','enrolled_university','education_level','last_new_job','training_hours','target']\r\n",
    "# model_cols_t = ['enrollee_id','city','city_development_index','gender','relevent_experience','enrolled_university','education_level','last_new_job','training_hours']\r\n",
    "# df_train = df_train[model_cols]\r\n",
    "# df_target = df_target[model_cols_t]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Entranamiento de modelo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## idenficación de variables categoricas typadas como númericas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# idenficación de variables categoricas identificadas como númericas\r\n",
    "df_train.enrollee_id = df_train.enrollee_id.astype('category')\r\n",
    "df_train.target = df_train.target.astype('category')\r\n",
    "\r\n",
    "# replicamos en el set objetivo\r\n",
    "df_target.enrollee_id = df_target.enrollee_id.astype('category')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def heat_map(df):\r\n",
    "    corr = df.corr()\r\n",
    "    fig, ax = plt.subplots(figsize=(15,8))\r\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\r\n",
    "    sns.heatmap(ax=ax, data=corr, annot=True, cmap='Pastel1_r', mask=mask)\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# heat_map(df_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Depuración en set de entranamiento de datos que no existen en el set objetivo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# depuración de variable city\r\n",
    "df_train = df_train.copy()\r\n",
    "# Eliminamos del set de entrenamiento las ciudades que no existen en el set objetivo\r\n",
    "print(df_train.shape)\r\n",
    "drop_list = df_target.city.value_counts().index.tolist()\r\n",
    "df_train.drop(df_train[~df_train.city.isin(drop_list)].index, inplace = True)\r\n",
    "print(df_train.shape)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(15326, 14)\n",
      "(15242, 14)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Balanceo de dataset de entrenamiento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Dividimos el dataset 2 para cada tipo de datos\r\n",
    "total_rows_0, total_rows_1 = df_train.target.value_counts()\r\n",
    "df_class_0 = df_train[df_train.target == 0]\r\n",
    "df_class_1 = df_train[df_train.target == 1]\r\n",
    "print(df_class_0.target.count())\r\n",
    "print(df_class_1.target.count())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "11435\n",
      "3807\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # creamos un dataset balanceado utilizando undersample (eliminamos registros al set de 0s)\r\n",
    "# df_sample_0 = resample(df_class_0, replace=True, n_samples=total_rows_1, random_state=15)\r\n",
    "# print('resample minority: ', df_sample_0.target.count())\r\n",
    "# df_train = pd.concat([df_sample_0, df_class_1], axis=0)\r\n",
    "# print('set balanced: ', df_train.target.count())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# creamos un dataset balanceado utilizando oversample (agregamos registros al set de 1s)\r\n",
    "df_sample_1 = resample(df_class_1, replace=True, n_samples=total_rows_0, random_state=15)\r\n",
    "print('resample minority: ', df_sample_1.target.count())\r\n",
    "df_train = pd.concat([df_sample_1, df_class_0], axis=0)\r\n",
    "print('set balanced: ', df_train.target.count())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "resample minority:  11435\n",
      "set balanced:  22870\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## tratamiento de nullos y vacios"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def transform_nulls(df):\r\n",
    "    df = df.copy()\r\n",
    "    df.gender = df.gender.fillna('Other')\r\n",
    "    df.enrolled_university = df.enrolled_university.fillna('no_enrollment')\r\n",
    "    df.education_level = df.education_level.fillna('Undefined')\r\n",
    "    df.major_discipline = df.major_discipline.fillna('Other')\r\n",
    "    df.experience = df.experience.fillna('Other')\r\n",
    "    df.company_size = df.company_size.fillna('Other')\r\n",
    "    df.company_type = df.company_type.fillna('Other')\r\n",
    "    df.last_new_job = df.last_new_job.fillna('never')\r\n",
    "    return df\r\n",
    "\r\n",
    "df_train = transform_nulls(df_train)\r\n",
    "df_target = transform_nulls(df_target)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Eliminación de outliers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       city_development_index  training_hours\n",
       "count            22870.000000    22870.000000\n",
       "mean                 0.806105       64.803061\n",
       "std                  0.133983       59.474954\n",
       "min                  0.448000        1.000000\n",
       "25%                  0.624000       23.000000\n",
       "50%                  0.893000       47.000000\n",
       "75%                  0.920000       88.000000\n",
       "max                  0.949000      336.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>training_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22870.000000</td>\n",
       "      <td>22870.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.806105</td>\n",
       "      <td>64.803061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.133983</td>\n",
       "      <td>59.474954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.448000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.624000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.893000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.920000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.949000</td>\n",
       "      <td>336.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# identificamos las columnas númericas y las categoricas\r\n",
    "n_cols = ['training_hours']\r\n",
    "\r\n",
    "# Eliminamos los outliers de las columnas númericas\r\n",
    "z_scores = stats.zscore(df_train[n_cols])\r\n",
    "abs_z_scores = np.abs(z_scores)\r\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\r\n",
    "df_train = df_train[filtered_entries]\r\n",
    "df_train.describe()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_sample' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-7c7fa5f0a473>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Eliminamos los outliers de las columnas númericas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mz_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mabs_z_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfiltered_entries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mabs_z_scores\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_sample' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Escalamiento de variable númericas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Escalamos las variables númericas\r\n",
    "scale = StandardScaler()\r\n",
    "df_train['training_hours'] = scale.fit_transform(df_train.training_hours.values.reshape(-1,1))\r\n",
    "\r\n",
    "# Escalamos las variables del set objetivo \r\n",
    "df_target['training_hours'] = scale.fit_transform(df_target.training_hours.values.reshape(-1,1))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Eliminamos del set de entrenamiento las columnas que no existen en el set objetivo\r\n",
    "print(df_train.shape)\r\n",
    "drop_list = df_target.city.value_counts().index.tolist()\r\n",
    "df_train.drop(df_train[~df_train.city.isin(drop_list)].index, inplace = True)\r\n",
    "print(df_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(7614, 14)\n",
      "(7614, 14)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#****************************************************************\r\n",
    "#****************************************************************\r\n",
    "# revisemos como se estan normalizando los datos\r\n",
    "df_train.to_csv('./outputs/df_train_temp.csv', index=False)\r\n",
    "df_target.to_csv('./outputs/df_target_temp.csv', index=False)\r\n",
    "#****************************************************************\r\n",
    "#****************************************************************"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['enrollee_id', 'city', 'city_development_index', 'gender',\n",
       "       'relevent_experience', 'enrolled_university', 'education_level',\n",
       "       'major_discipline', 'experience', 'company_size', 'company_type',\n",
       "       'last_new_job', 'training_hours', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generación de variables dummy\r\n",
    "dummy_cols   = ['city','gender','relevent_experience','enrolled_university','education_level','major_discipline','experience','company_size','company_type','last_new_job']\r\n",
    "df_dummy = pd.get_dummies(data=df_train, columns=dummy_cols)\r\n",
    "df_dummy_t = pd.get_dummies(data=df_target, columns=dummy_cols)\r\n",
    "# df_dummy.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# igualamos las columnas del set de entrenamiento y objetivo\r\n",
    "target_cols = df_dummy_t.columns.tolist()\r\n",
    "df_dummy = df_dummy[target_cols]\r\n",
    "df_dummy = pd.concat([df_dummy,df_train.target.reindex(df_dummy.index)], axis=1)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"['city_city_8', 'city_city_121'] not in index\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-accfe3c43f68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# igualamos las columnas del set de entrenamiento y objetivo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtarget_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_dummy_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_dummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_dummy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf_dummy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_dummy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_dummy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['city_city_8', 'city_city_121'] not in index\""
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carga de datos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# creamos sets de entrenamiento\r\n",
    "X = df_dummy.drop(['enrollee_id','target'], axis=1).to_numpy()\r\n",
    "y = df_dummy.target.to_numpy()\r\n",
    "# creamos set objetivo\r\n",
    "X_t = df_dummy_t.drop(['enrollee_id'], axis=1).to_numpy()\r\n",
    "\r\n",
    "# generamos los sets de entreamiento y test\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelo de Regresión Logistica"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Entrenamos el modelo de Regresión Logistica\r\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=1000)\r\n",
    "logreg.fit(X_train, y_train)\r\n",
    "logreg.score(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7747595102754701"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Hacemos las predicciones con el set de pruebas\r\n",
    "y_pred = logreg.predict(X_test)\r\n",
    "print(logreg.score(X_test, y_test))\r\n",
    "confusion_matrix(y_test, y_pred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7586357673808483\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1729,  558],\n",
       "       [ 546, 1741]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Revisamos el reporte de clasificación\r\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.76      0.76      2287\n",
      "         1.0       0.76      0.76      0.76      2287\n",
      "\n",
      "    accuracy                           0.76      4574\n",
      "   macro avg       0.76      0.76      0.76      4574\n",
      "weighted avg       0.76      0.76      0.76      4574\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predicciones del set objetivo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carga de datos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# generamos las predicciones del set objetivo\r\n",
    "y_pred_t = logreg.predict(X_t)\r\n",
    "# Agregamos las etiquetas de predicción al df\r\n",
    "df_target['target'] = y_pred_t\r\n",
    "# creamos el df de submission\r\n",
    "df_submission = df_target[['enrollee_id','target']]\r\n",
    "df_submission.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  enrollee_id  target\n",
       "0       23603     1.0\n",
       "1       22499     0.0\n",
       "2       10465     1.0\n",
       "3        8293     0.0\n",
       "4        4246     0.0\n",
       "5       29306     0.0\n",
       "6       23118     1.0\n",
       "7       32832     0.0\n",
       "8       13380     0.0\n",
       "9       16102     1.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23603</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10465</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8293</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4246</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29306</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23118</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32832</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16102</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_submission.target.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0    2434\n",
       "1.0    1398\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# creamos el archivo csv para submission en el portal kaggle\r\n",
    "df_submission.to_csv('./outputs/submission_21.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "376f5b0795f81aa7b5d99e448d6274743a66c9892fd26cf11e505993f41df5fa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}